{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Chunking?\n",
    "## 1) Chunking is a process of extracting phrases from unstructured text.\n",
    "## 2) Chunking works on top of POS tagging, it uses pos-tags as input and provides chunks as output.\n",
    "## 3) Chunking is very important when you want to extract information from text such as Locations, Person Names etc. In NLP called Named Entity Extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Types oc Chunking:-\n",
    "\n",
    "1) Chunking Up:-\n",
    "   1) Abstract the information.\n",
    "   2) Zoom out Information.\n",
    "   3) Overview the situation.\n",
    "2) Chunking Down:-\n",
    "   1) Get details Information.\n",
    "   2) Zoom in about Information.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun phrase Chunker\n",
    "1) Difining chunk gammer.\n",
    "\n",
    "2) creating chunk parser.\n",
    "\n",
    "3) We will get TREE structue outout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corona is sery dangerous virus in 21st century.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "text=\"Corona is sery dangerous virus in 21st century.\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the grammer for noun phrse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP:{<DT>?<JJ>/<NN>} #NP\n"
     ]
    }
   ],
   "source": [
    "#grammer=\"NP:{<DT>?<JJ>*<NN>} #NP\"\n",
    "grammer=\"NP:{<DT>?<JJ>/<NN>} #NP\"\n",
    "print(grammer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_parser=nltk.RegexpParser(grammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Corona', 'NNP'), ('is', 'VBZ'), ('sery', 'RB'), ('dangerous', 'JJ'), ('virus', 'NN'), ('in', 'IN'), ('21st', 'JJ'), ('century', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence=nltk.pos_tag(nltk.word_tokenize(text))\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Corona/NNP\n",
      "  is/VBZ\n",
      "  sery/RB\n",
      "  dangerous/JJ\n",
      "  virus/NN\n",
      "  in/IN\n",
      "  21st/JJ\n",
      "  century/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "tree_output=simple_parser.parse(sentence)\n",
    "print(tree_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_output.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
